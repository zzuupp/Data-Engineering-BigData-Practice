{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5lqEzqQuBqMDf9MvhS1v1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzuupp/Data-Engineering-BigData-Practice/blob/main/Spark/Spark_Beginner_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark : ì´ˆë³´ììš© íŠœí† ë¦¬ì–¼"
      ],
      "metadata": {
        "id": "PqmluqZBbeq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "> ì•„ì´ë¦¬ìŠ¤ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬, ìŠ¤íŒŒí¬ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì‚´í´ë³´ê¸°."
      ],
      "metadata": {
        "id": "_JDC7nvOb0Dy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸°\n",
        "* ìŠ¤íŒŒí¬ ì„¸ì…˜ êµ¬ì¶•\n",
        "* ë°ì´í„° ë¡œë“œ\n",
        "* ë°ì´í„° íƒìƒ‰ ë° ì¤€ë¹„\n",
        "* í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
        "* ë°ì´í„° ìŠ¤ì¼€ì¼ë§\n",
        "* ë°ì´í„° ë¶„í• \n",
        "* ëª¨ë¸ êµ¬ì¶•, í›ˆë ¨ ë° í‰ê°€"
      ],
      "metadata": {
        "id": "MoZLtkZubqUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "install Apache Spark"
      ],
      "metadata": {
        "id": "PtiWmKLkbzqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pyspark"
      ],
      "metadata": {
        "id": "EQFd2IqKcDlU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "9Ou3OwWLcG3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Apache Spark Libraries\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Apache Spark ML CLassifier Libraries\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, NaiveBayes\n",
        "\n",
        "# Apache Spark Evaluation Library\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Apache Spark Feature libraries\n",
        "from pyspark.ml.feature import StandardScaler, StringIndexer, VectorAssembler, VectorIndexer, OneHotEncoder\n",
        "\n",
        "# Apache Spark 'DenseVector'\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "\n",
        "# Data Split Libraries\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tabulating Data\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Garbage\n",
        "import gc"
      ],
      "metadata": {
        "id": "gMbnodeFcOWr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Spark Session"
      ],
      "metadata": {
        "id": "6xrG2Rp6hLss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Spark Session : ìŠ¤íŒŒí¬ ì•±ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì§„ì…ì .\n",
        "# ë‚´ê°€ ì‚¬ìš©í•  sparkì˜ ì´ë¦„ ì§€ì •.\n",
        "# 'spark.executor.memory' : ì‹¤í–‰ ì‹œ, ê°ê°ì˜ ì‘ì—… í”„ë¡œì„¸ìŠ¤ (Executor)ì— í• ë‹¹ ë©”ëª¨ë¦¬ í¬ê¸° ì„¤ì •.\n",
        "#                           í´ëŸ¬ìŠ¤í„° ëª¨ë“œì—ì„œëŠ” ì—¬ëŸ¬ Executorê°€ ëœ¨ê¸° ë•Œë¬¸ì— ì´ ì„¤ì •ì´ ì¤‘ìš”.\n",
        "\n",
        "# \"spark.excutor.cores\" : Executorê°€ ì‚¬ìš©í•˜ëŠ” CPU ì½”ì–´ ìˆ˜ë¥¼ ì„¤ì •\n",
        "\n",
        "# .getOrCreate() : ê°™ì€ ì´ë¦„ì˜ SparkSession ì´ ìˆë‹¤ë©´ ê·¸ê±¸ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ë§Œë“¤ì–´ì¤˜!\n",
        "\n",
        "# SparkSession : ê³ ìˆ˜ì¤€ API(DataFrame SQL) ë“±ì„ ë‹¤ë£¸. *ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì¶”ìƒí™”ëœ ì¸í„°í˜ì´ìŠ¤\n",
        "spark = (SparkSession.builder\n",
        "                            .appName('Apach Spark Beginner Tutorial')\n",
        "                            .config('spark.executor.memory', '1G')\n",
        "                            .config(\"spark.executor.cores\", '4')\n",
        "                            .getOrCreate())"
      ],
      "metadata": {
        "id": "6cu3eMKdnID1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sparkContext : ìŠ¤íŒŒí¬ ì—”ì§„ê³¼ ì§ì ‘ ì—°ê²°ëœ ì»¨íŠ¸ë¡¤ ê°ì²´\n",
        "# .setLogLevel : ë¡œê·¸ ì¶œë ¥ ìˆ˜ì¤€ì„ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜\n",
        "#               ('INFO') â†’ ë¡œê·¸ ìˆ˜ì¤€ì„ INFOë¡œ ë§ì¶°ë¼ (ë§ì€ ì‹¤í–‰ ì •ë³´ê°€ ë³´ì„)\n",
        "spark.sparkContext.setLogLevel('INFO')"
      ],
      "metadata": {
        "id": "fbzvLJ_3pMFN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Load"
      ],
      "metadata": {
        "id": "uoQSV2Svvb-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O iris.csv https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8leXCLE3FKn",
        "outputId": "ece970ae-203b-4476-d9c4-66290dcd340c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-29 06:56:27--  https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3716 (3.6K) [text/plain]\n",
            "Saving to: â€˜iris.csvâ€™\n",
            "\n",
            "\riris.csv              0%[                    ]       0  --.-KB/s               \riris.csv            100%[===================>]   3.63K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-09-29 06:56:27 (44.5 MB/s) - â€˜iris.csvâ€™ saved [3716/3716]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# .option('header', 'true') : ì²«ì¤„ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì‚¬ìš©(ì—†ë‹¤ë©´ c0, c1...ì´ëŸ°ì‹ì„)\n",
        "# .option('inferSchema', 'true') \\ # ë¬¸ìì—´ì´ ì•„ë‹Œ ìˆ«ì / ì‹¤ìˆ˜ ë“±ì„ ìë™ìœ¼ë¡œ íƒ€ì… ì¶”ë¡ .\n",
        "data = (spark.read.format(\"csv\")\n",
        "        .option('header', 'true')\n",
        "        .option('inferSchema', 'true')\n",
        "        .load('iris.csv'))\n",
        "\n",
        "# .cache() â†’ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ì˜¬ë ¤ë‘ê³  ì´í›„ ì—°ì‚° ì‹œ ì¬ì‚¬ìš© (ì†ë„ â†‘)\n",
        "data.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah8DaHW7vg0O",
        "outputId": "bde6dd62-a0de-4d1b-84f8-92938e8a7f8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[sepal_length: double, sepal_width: double, petal_length: double, petal_width: double, species: string]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration & Preparation"
      ],
      "metadata": {
        "id": "HQZ-0HoN2I7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XU3J5jT3gx0",
        "outputId": "a1ab0742-ab3d-47f6-a7de-87caa887455e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Type\n",
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW1kA1V27DaN",
        "outputId": "4c6d8254-5981-4452-cb19-38ed81ed37fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sepal_length: double (nullable = true)\n",
            " |-- sepal_width: double (nullable = true)\n",
            " |-- petal_length: double (nullable = true)\n",
            " |-- petal_width: double (nullable = true)\n",
            " |-- species: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display recodes\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK7btAtt77rN",
        "outputId": "2195a53b-4c45-41ae-f5d5-a4ad5c4c0d72"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Record per Species\n",
        "data.groupBy('species').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11rZCXju8QrG",
        "outputId": "78bf580c-16d8-45be-f04c-3def0a066db3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|   species|count|\n",
            "+----------+-----+\n",
            "| virginica|   50|\n",
            "|versicolor|   50|\n",
            "|    setosa|   50|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Summary Stats\n",
        "\n",
        "# stddev : í‘œì¤€í¸ì°¨.\n",
        "#     ex : sepal_lengthì˜ í‰ê·  ê°’ì€ 5.84cmì¸ë° Â± 0.828 ë²”ìœ„ë‚´ì— ë¶„í¬\n",
        "\n",
        "data.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzrvvbAl8Zr-",
        "outputId": "0255905c-455e-4610-eaa7-4e82351fda8a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-------------------+------------------+------------------+---------+\n",
            "|summary|      sepal_length|        sepal_width|      petal_length|       petal_width|  species|\n",
            "+-------+------------------+-------------------+------------------+------------------+---------+\n",
            "|  count|               150|                150|               150|               150|      150|\n",
            "|   mean| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|     NULL|\n",
            "| stddev|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|     NULL|\n",
            "|    min|               4.3|                2.0|               1.0|               0.1|   setosa|\n",
            "|    max|               7.9|                4.4|               6.9|               2.5|virginica|\n",
            "+-------+------------------+-------------------+------------------+------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì˜ˆì¸¡ì„ ì‹œì‘í•˜ê¸° ìœ„í•´, Species ì¦‰ Label ì»¬ëŸ¼ì€ ìˆ«ì ê°’ì´ì–´ì•¼ í•œë‹¤ (ëª¨ë¸ì€ ë¬¸ìì—´ì„ ì‹«ì–´í•œë‹¤!).\n",
        "\n",
        "\n",
        "ì´ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” Species ì»¬ëŸ¼ì— ë¬¸ìì—´ ì¸ë±ì‹±(String Indexing) ì„ ì ìš©í•  ê²ƒì´ë‹¤."
      ],
      "metadata": {
        "id": "NUNEKKkb8iAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#String Indexing the Species column\n",
        "SIndexer = StringIndexer(inputCol='species', outputCol = 'species_indx')\n",
        "\n",
        "# .fit(data) ìœ„ì—ì„œ ì§€ì • ê·œì¹™ì„ í•™ìŠµë§Œ í•¨ (ì•„ì§ ë³€í™˜ x)\n",
        "# .transform(data) = ë³€í™˜ ê·œì¹™ì„ ì ìš©í•´ì„œ ìƒˆ ì»¬ëŸ¼ ìƒì„± (í•˜ì§€ë§Œ ì§„ì§œ ê³„ì‚°ì€ Action ë•Œ ì‹¤í–‰).\n",
        "# ì¦‰ ì‹¤ì œ ê³„ì‚°ì€ ì´ ì‹œì ì—ì„œë„ ì•ˆì¼ì–´ë‚¨, **ì‹¤í–‰ ê³„íš(Execution Plan)**ì„ DAG(Directed Acyclic Graph)ë¡œ ì €ì¥í•œ ê²ƒ.\n",
        "data = SIndexer.fit(data).transform(data)\n",
        "\n",
        "# ë¹„ë¡œì†Œ ì‹¤í–‰.\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9mFxcvt9So3",
        "outputId": "9537f9d8-e1ce-49a2-bffe-715e01a04bb1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-------+------------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species|species_indx|\n",
            "+------------+-----------+------------+-----------+-------+------------+\n",
            "|         5.1|        3.5|         1.4|        0.2| setosa|         0.0|\n",
            "|         4.9|        3.0|         1.4|        0.2| setosa|         0.0|\n",
            "|         4.7|        3.2|         1.3|        0.2| setosa|         0.0|\n",
            "|         4.6|        3.1|         1.5|        0.2| setosa|         0.0|\n",
            "|         5.0|        3.6|         1.4|        0.2| setosa|         0.0|\n",
            "+------------+-----------+------------+-----------+-------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì¦‰, **Spark**ëŠ” **ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ (SQL í…Œì´ë¸” ëŠë‚Œ)**, PandasëŠ” ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ (ìœ ì—°)ì´ë¼ ìƒê¸´ ì°¨ì´"
      ],
      "metadata": {
        "id": "kwrwvM3i_4YU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OqkxA4pr_7Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "eMgqcElq9yD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "The Spark model needs two columns: â€œlabelâ€ and â€œfeaturesâ€ and we are not going to do much feature engineering because we want to focus on the mechanics of training the model in Spark. So, creating a seperate dataframe with re-ordered columns, then defining an input data using Dense Vector. A Dense Vector is a local vector that is backed by a double array that represents its entry values. In other words, it's used to store arrays of values for use in PySpark.\n",
        "\n",
        "\n",
        "\n",
        "ìŠ¤íŒŒí¬ì—ì„œ ëª¨ë¸ì„ í•™ìŠµí•˜ë ¤ë©´ â€œlabelâ€ ê³¼ â€œfeaturesâ€ ë‘ ì»¬ëŸ¼ì´ ê¼­ í•„ìš”í•˜ë‹¤.\n",
        "\n",
        "ì´ë²ˆì—ëŠ” ëª¨ë¸ í•™ìŠµ ê³¼ì •ì„ ìµíˆëŠ” ë° ì§‘ì¤‘í•  ê±°ë¼ ë³µì¡í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì€ ë”°ë¡œ í•˜ì§€ ì•ŠëŠ”ë‹¤.\n",
        "\n",
        "ê·¸ë˜ì„œ ì»¬ëŸ¼ ìˆœì„œë¥¼ ì¬ë°°ì¹˜í•˜ì—¬ ë³„ë„ì˜ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„± í›„, ì…ë ¥ ë°ì´í„°ëŠ” Dense Vectorë¼ëŠ” í˜•íƒœë¡œ ì •ì˜.\n",
        "\n",
        "Dense VectorëŠ” ë‚´ë¶€ì ìœ¼ë¡œ double ë°°ì—´ì„ ê¸°ë°˜ìœ¼ë¡œ ê°’ì„ ë‹´ëŠ” ë¡œì»¬ ë²¡í„°ì¸ë°,\n",
        "\n",
        "ì‰½ê²Œ ë§í•´ PySparkì—ì„œ ì—¬ëŸ¬ ê°’ë“¤ì„ ë¬¶ì–´ ì €ì¥í•˜ê³  ëª¨ë¸ì— ë„£ì„ ë•Œ ì“°ì´ëŠ” ìë£Œ êµ¬ì¡°ë¼ê³  ë³´ë©´ ëœë‹¤"
      ],
      "metadata": {
        "id": "boIOxPF6DGO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a seperate dataframe with re-ordered columns\n",
        "df = data.select('species_indx', 'sepal_length', 'sepal_width', 'petal_length', 'petal_width')\n",
        "\n",
        "# Inspect the dataframe\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqWQJSTn_7Ah",
        "outputId": "b4422f9e-7125-4232-de15-737ea71dffed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+-----------+------------+-----------+\n",
            "|species_indx|sepal_length|sepal_width|petal_length|petal_width|\n",
            "+------------+------------+-----------+------------+-----------+\n",
            "|         0.0|         5.1|        3.5|         1.4|        0.2|\n",
            "|         0.0|         4.9|        3.0|         1.4|        0.2|\n",
            "|         0.0|         4.7|        3.2|         1.3|        0.2|\n",
            "|         0.0|         4.6|        3.1|         1.5|        0.2|\n",
            "|         0.0|         5.0|        3.6|         1.4|        0.2|\n",
            "+------------+------------+-----------+------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Observe that the species column which is our label (aka Target) is now at beginning of the dataframe\n",
        "\n"
      ],
      "metadata": {
        "id": "5POtopVWGXBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the `input_data` as Dense Vector\n",
        "input_data = df.rdd.map(lambda x: (x[0], DenseVector(x[1:])))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "***\n",
        "ğŸ” DenseVectorë€?\n",
        "Spark MLì—ì„œ ì“°ì´ëŠ” íŠ¹ìˆ˜í•œ ë²¡í„° ìë£Œêµ¬ì¡°.\n",
        "ë‚´ë¶€ì ìœ¼ë¡œ double ë°°ì—´ ê¸°ë°˜.\n",
        "ë³´í†µ features ì»¬ëŸ¼ì´ DenseVector í˜•íƒœì—¬ì•¼ ëª¨ë¸ì— ë„£ì„ ìˆ˜ ìˆì–´ìš”\n",
        "\n",
        "\n",
        "***\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "\n",
        "v = DenseVector([1.0, 2.0, 3.0])\n",
        "print(v)\n",
        "# [1.0,2.0,3.0]\n",
        "print(type(v))\n",
        "# <class 'pyspark.ml.linalg.DenseVector'>\n",
        "\n",
        "\n",
        "***\n",
        "df.rddë¡œ ë°”ê¾¸ë©´ DataFrameì˜ ê° Rowê°€ íŒŒì´ì¬ íŠœí”Œ ë¹„ìŠ·í•œ êµ¬ì¡°ë¡œ ë°”ë€œ.\n",
        "row = (0.0, 5.1, 3.5, 1.4, 0.2)  # RDDì˜ í•œ í–‰\n",
        "\n",
        "row[0]     # 0.0 â†’ species_indx (label)\n",
        "row[1:]    # (5.1, 3.5, 1.4, 0.2) â†’ features\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9JCx561xGx0I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ab3b74e1-9eef-4978-9deb-82af2e01aea8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n***\\nğŸ” DenseVectorë€?\\nSpark MLì—ì„œ ì“°ì´ëŠ” íŠ¹ìˆ˜í•œ ë²¡í„° ìë£Œêµ¬ì¡°.\\në‚´ë¶€ì ìœ¼ë¡œ double ë°°ì—´ ê¸°ë°˜.\\në³´í†µ features ì»¬ëŸ¼ì´ DenseVector í˜•íƒœì—¬ì•¼ ëª¨ë¸ì— ë„£ì„ ìˆ˜ ìˆì–´ìš”\\n\\n\\n***\\nfrom pyspark.ml.linalg import DenseVector\\n\\nv = DenseVector([1.0, 2.0, 3.0])\\nprint(v)\\n# [1.0,2.0,3.0]\\nprint(type(v))\\n# <class 'pyspark.ml.linalg.DenseVector'>\\n\\n\\n***\\ndf.rddë¡œ ë°”ê¾¸ë©´ DataFrameì˜ ê° Rowê°€ íŒŒì´ì¬ íŠœí”Œ ë¹„ìŠ·í•œ êµ¬ì¡°ë¡œ ë°”ë€œ.\\nrow = (0.0, 5.1, 3.5, 1.4, 0.2)  # RDDì˜ í•œ í–‰\\n\\nrow[0]     # 0.0 â†’ species_indx (label)\\nrow[1:]    # (5.1, 3.5, 1.4, 0.2) â†’ features\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Observe the definition of the Dense Vector.\n",
        "\n",
        "\n",
        "So,when we create a new indexed dataframe(below) the machine understands\n",
        "\n",
        "\n",
        "that the first column is a Label (Target) and the remaining columns are Features."
      ],
      "metadata": {
        "id": "NaVfBJLnvoOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new Indexed DataFrame\n",
        "df_indx = spark.createDataFrame(input_data, ['label', 'features'])"
      ],
      "metadata": {
        "id": "5U1g9VHivptU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_indx.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u8n-yr8xIAz",
        "outputId": "4ada5fe3-93ce-408b-e157-3e7cc6f3fd4b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|label|         features|\n",
            "+-----+-----------------+\n",
            "|  0.0|[5.1,3.5,1.4,0.2]|\n",
            "|  0.0|[4.9,3.0,1.4,0.2]|\n",
            "|  0.0|[4.7,3.2,1.3,0.2]|\n",
            "|  0.0|[4.6,3.1,1.5,0.2]|\n",
            "|  0.0|[5.0,3.6,1.4,0.2]|\n",
            "+-----+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Scaling\n"
      ],
      "metadata": {
        "id": "cXCaBBGhxMdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Standard Scaler\n",
        "stdScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
        "\n",
        "# Fit and transform the data\n",
        "scaler = stdScaler.fit(df_indx)\n",
        "\n",
        "# Transform the dataframe\n",
        "df_scaled = scaler.transform(df_indx)"
      ],
      "metadata": {
        "id": "xxbALxDOyo4q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ESjsuezANBy",
        "outputId": "6781f136-2da5-442a-faed-6d5aacff6f53"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+--------------------+\n",
            "|label|         features|     features_scaled|\n",
            "+-----+-----------------+--------------------+\n",
            "|  0.0|[5.1,3.5,1.4,0.2]|[6.15892840883878...|\n",
            "|  0.0|[4.9,3.0,1.4,0.2]|[5.9174018045706,...|\n",
            "|  0.0|[4.7,3.2,1.3,0.2]|[5.67587520030241...|\n",
            "|  0.0|[4.6,3.1,1.5,0.2]|[5.55511189816831...|\n",
            "|  0.0|[5.0,3.6,1.4,0.2]|[6.03816510670469...|\n",
            "+-----+-----------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the Features column\n",
        "df_scaled = df_scaled.drop('features')"
      ],
      "metadata": {
        "id": "vG8pedU5AW1w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UTmtltvAoHR",
        "outputId": "17240408-fe24-4d9c-9461-491d93047df6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|     features_scaled|\n",
            "+-----+--------------------+\n",
            "|  0.0|[6.15892840883878...|\n",
            "|  0.0|[5.9174018045706,...|\n",
            "|  0.0|[5.67587520030241...|\n",
            "|  0.0|[5.55511189816831...|\n",
            "|  0.0|[6.03816510670469...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Split\n",
        "---\n",
        "Just like always, before building a model we shall split our scaled dataset into training & test sets.\n",
        "\n",
        " Training Dataset = 90% Test Dataset = 10%"
      ],
      "metadata": {
        "id": "I-v6zqyyApZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df_scaled.randomSplit([0.9, 0.1], seed = 12345)"
      ],
      "metadata": {
        "id": "J3eZT3ScA7Wc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GgGV9_4Bz0-",
        "outputId": "85d4e9ad-baad-4e70-e0f7-5813dc85f521"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|     features_scaled|\n",
            "+-----+--------------------+\n",
            "|  0.0|[5.19282199176603...|\n",
            "|  0.0|[5.31358529390013...|\n",
            "|  0.0|[5.31358529390013...|\n",
            "|  0.0|[5.31358529390013...|\n",
            "|  0.0|[5.43434859603422...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build, Train & Evaluate Model\n",
        "---"
      ],
      "metadata": {
        "id": "UcRF4-G3B5x3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step we will create multiple models, train them on our scaled dataset and then compare their accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "aA4rr5KdNFfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ['Decision Tree', 'Random Forest', 'Naive Bayes']\n",
        "model_results = []"
      ],
      "metadata": {
        "id": "cCQxQCPmCAv-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decision Tree Classifier"
      ],
      "metadata": {
        "id": "-Z3idoxuZ4lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Classifier\n",
        "dtc = DecisionTreeClassifier(labelCol = 'label', featuresCol = 'features_scaled')\n",
        "dtc_model = dtc.fit(train_data)\n",
        "dtc_pred = dtc_model.transform(test_data)\n",
        "\n",
        "# Evaluate the Model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol = 'label',\n",
        "                                              predictionCol = 'prediction',\n",
        "                                              metricName = 'accuracy')\n",
        "\n",
        "dtc_acc = evaluator.evaluate(dtc_pred)\n",
        "\n",
        "# print Decision Tree Classifier Accuracy = {:.2%}.format(dtc_acc)\n",
        "model_results.extend([model[0], '{:.2%}'.format(dtc_acc)])\n"
      ],
      "metadata": {
        "id": "zX9Yv_1UZ7w0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest Classifier"
      ],
      "metadata": {
        "id": "eNJzy6F6NUtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(labelCol = 'label', featuresCol = 'features_scaled', numTrees= 10)\n",
        "\n",
        "rfc_model = rfc.fit(train_data)\n",
        "\n",
        "rfc_pred = rfc_model.transform(test_data)\n",
        "\n",
        "# Evaluate the Model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label',\n",
        "                                              predictionCol='prediction',\n",
        "                                              metricName= 'accuracy')\n",
        "\n",
        "rfc_acc = evaluator.evaluate(rfc_pred)\n",
        "\n",
        "model_results.extend([[model[1], '{:.2%}'.format(rfc_acc)]])"
      ],
      "metadata": {
        "id": "Z5dik38ROvEm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Naive Bayes Classifier\n"
      ],
      "metadata": {
        "id": "o96StMsrP_gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nbc = NaiveBayes(smoothing= 1.0,\n",
        "                 modelType = 'multinomial',\n",
        "                 labelCol= 'label',\n",
        "                 featuresCol = 'features_scaled')\n",
        "\n",
        "nbc_model = nbc.fit(train_data)\n",
        "\n",
        "nbc_pred = nbc_model.transform(test_data)\n",
        "\n",
        "# Evaluate the Model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label',\n",
        "                                              predictionCol='prediction',\n",
        "                                              metricName= 'accuracy')\n",
        "\n",
        "nbc_acc = evaluator.evaluate(nbc_pred)\n",
        "model_results.extend([[model[2], '{:.2%}'.format(nbc_acc)]])"
      ],
      "metadata": {
        "id": "njUb2e40POEL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU07ZiaIPzJI",
        "outputId": "70b84155-916b-458a-95bc-28070b655b22"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "442"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tabulate([model_results], headers = ['Model', 'Accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46eIr7LCQDOm",
        "outputId": "9a3b7ccb-604e-49de-d180-95c5f2a2b2ba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Model                         Accuracy\n",
            "-------------  ------  ----------------------------  --------------------------\n",
            "Decision Tree  90.91%  ['Random Forest', '100.00%']  ['Naive Bayes', '100.00%']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j52qSHI8QKio"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}